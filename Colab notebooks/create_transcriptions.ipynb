{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "66d555cf2d4e4d109fa9e5dc6a8a6d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7959a795dd74a25b4e6af32adc70b06",
              "IPY_MODEL_a1eab59c46b4468dadfa7cc2a7898938",
              "IPY_MODEL_7c0c0b60823c419e8fe23127488a29ae"
            ],
            "layout": "IPY_MODEL_2a9f5dbef36342a2a5da59d80e5ccb27"
          }
        },
        "a7959a795dd74a25b4e6af32adc70b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c39f8c7b9ff453bb20adee6895f5817",
            "placeholder": "​",
            "style": "IPY_MODEL_ffd24069c6bc40c5a70060ff5b476f5a",
            "value": "tokenizer.json: 100%"
          }
        },
        "a1eab59c46b4468dadfa7cc2a7898938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24f3f3fc5b5648859fe2a5bcc344f6a4",
            "max": 2480466,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ab7ac58988c43ae9fd016023303a146",
            "value": 2480466
          }
        },
        "7c0c0b60823c419e8fe23127488a29ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_024971c5573241f09406503eb8cbf408",
            "placeholder": "​",
            "style": "IPY_MODEL_251f1cdd179748b1bd537895409219df",
            "value": " 2.48M/2.48M [00:00&lt;00:00, 6.50MB/s]"
          }
        },
        "2a9f5dbef36342a2a5da59d80e5ccb27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c39f8c7b9ff453bb20adee6895f5817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd24069c6bc40c5a70060ff5b476f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24f3f3fc5b5648859fe2a5bcc344f6a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab7ac58988c43ae9fd016023303a146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "024971c5573241f09406503eb8cbf408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251f1cdd179748b1bd537895409219df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers faster_whisper torchaudio torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjxrMjtdQF44",
        "outputId": "f7b1f7fb-36b8-4f09-a8e9-540e092f89e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting faster_whisper\n",
            "  Downloading faster_whisper-1.0.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Collecting av<13,>=11.0 (from faster_whisper)\n",
            "  Downloading av-12.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<5,>=4.0 (from faster_whisper)\n",
            "  Downloading ctranslate2-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (192.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.3/192.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime<2,>=1.14 (from faster_whisper)\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster_whisper) (67.7.2)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster_whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (3.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, ctranslate2, av, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, onnxruntime, nvidia-cusolver-cu12, faster_whisper\n",
            "Successfully installed av-12.1.0 coloredlogs-15.0.1 ctranslate2-4.3.1 faster_whisper-1.0.2 humanfriendly-10.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip wavs2.zip"
      ],
      "metadata": {
        "id": "dQSgDuePQ6Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lOZqqenKUIk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from faster_whisper import WhisperModel\n",
        "import torchaudio\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmB_HnFBOmrq",
        "outputId": "f2b7dbca-168a-4ed7-9b7e-b121ab0329aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "True\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"VladS159/Whisper_medium_ro_VladS_10000_steps_multi_gpu_07_03_2024\"\n",
        "output_file_path = \"./transcriptions.txt\""
      ],
      "metadata": {
        "id": "jhq1Z-L5OoOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ct2-transformers-converter --model {model_id} --output_dir model_vlad --copy_files tokenizer_config.json preprocessor_config.json --quantization float16\n",
        "model = WhisperModel(\"model_vlad\", device=str(device), compute_type=\"float16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "66d555cf2d4e4d109fa9e5dc6a8a6d50",
            "a7959a795dd74a25b4e6af32adc70b06",
            "a1eab59c46b4468dadfa7cc2a7898938",
            "7c0c0b60823c419e8fe23127488a29ae",
            "2a9f5dbef36342a2a5da59d80e5ccb27",
            "7c39f8c7b9ff453bb20adee6895f5817",
            "ffd24069c6bc40c5a70060ff5b476f5a",
            "24f3f3fc5b5648859fe2a5bcc344f6a4",
            "7ab7ac58988c43ae9fd016023303a146",
            "024971c5573241f09406503eb8cbf408",
            "251f1cdd179748b1bd537895409219df"
          ]
        },
        "id": "N3raTbeIOv_f",
        "outputId": "561eea0d-5bbc-4b10-e3c7-f5918f38e8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 1.32k/1.32k [00:00<00:00, 7.56MB/s]\n",
            "model.safetensors: 100% 1.63G/1.63G [00:13<00:00, 120MB/s]\n",
            "generation_config.json: 100% 3.77k/3.77k [00:00<00:00, 21.7MB/s]\n",
            "tokenizer_config.json: 100% 283k/283k [00:00<00:00, 1.49MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 3.43MB/s]\n",
            "merges.txt: 100% 494k/494k [00:00<00:00, 7.67MB/s]\n",
            "normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 870kB/s]\n",
            "added_tokens.json: 100% 34.6k/34.6k [00:00<00:00, 127MB/s]\n",
            "special_tokens_map.json: 100% 2.19k/2.19k [00:00<00:00, 17.2MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "preprocessor_config.json: 100% 339/339 [00:00<00:00, 2.57MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66d555cf2d4e4d109fa9e5dc6a8a6d50"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(audio_file_path, file_index):\n",
        "  print(audio_file_path)\n",
        "  segments, info = model.transcribe(audio_file_path, beam_size=5, language=\"ro\", condition_on_previous_text=False)\n",
        "\n",
        "  transcription = \"\"\n",
        "  for segment in segments:\n",
        "      transcription += segment.text\n",
        "\n",
        "  with open(output_file_path, 'a', encoding='utf-8') as f:\n",
        "    print(transcription)\n",
        "    final_transcription =  f\"wavs/{file_index+142}.wav|{transcription}\"\n",
        "    f.write(final_transcription + '\\n')"
      ],
      "metadata": {
        "id": "aLwu07pROzXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_folder_path = \"./wavs2\"\n",
        "audio_files = [f for f in os.listdir(audio_folder_path) if f.endswith('.wav')]\n",
        "starting_index = 142\n",
        "\n",
        "for i, _ in enumerate(audio_files):\n",
        "    audio_path = f\"./wavs2/{i + starting_index}.wav\"\n",
        "    transcribe_audio(audio_path, i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8INfRzOYO4Ii",
        "outputId": "ff6046b1-d0d8-4438-da57-1727707e97e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./wavs2/142.wav\n",
            "O masă de aer tropical se extinde și se va intensifica din nou în zona țării noastre.\n",
            "./wavs2/143.wav\n",
            " vom avea temperaturi din ce în ce mai ridicate.\n",
            "./wavs2/144.wav\n",
            "Încă de azi vom vorbi despre temperaturi mai ridicate decât ieri.\n",
            "./wavs2/145.wav\n",
            "Mâine, ceva mai cald de atât, adică maxim treizeci sau treizeci și trei de grade.\n",
            "./wavs2/146.wav\n",
            "Azi ne așteptăm la o maximă în București, de douăzeci și opt sau douăzeci și nouă de grade.\n",
            "./wavs2/147.wav\n",
            " mâine, ne așteptăm la o temperatură chiar mai ridicată de atât.\n",
            "./wavs2/148.wav\n",
            "Vremea va deveni mai călduroasă, temperatura maximă se va ridica.\n",
            "./wavs2/149.wav\n",
            "Vom avea temperaturii ridicate și disconfort termic din ce în ce mai accentuat.\n",
            "./wavs2/150.wav\n",
            "Un borbat pasionat de istorie din China a făcut o descoperire alarmantă.\n",
            "./wavs2/151.wav\n",
            " După ce a plătit mai puțin de un dolar pentru patru cărți pe care le-a găsit.\n",
            "./wavs2/152.wav\n",
            "A găsit patru cărţi la un centrul de reciclare, iar cărţile conţineau documente cu informaţii militare secrete.\n",
            "./wavs2/153.wav\n",
            "Ministerul Securității de Stat din China, a dezvăluit joi povestea.\n",
            "./wavs2/154.wav\n",
            "Aceștia l-au lăudat pe bărbatul ieșit la pensie, care a raportat incidentul imediat.\n",
            "./wavs2/155.wav\n",
            "Postarea face parte dintr-o serie mai lungă de mesaje difuzate cu puternică atenţie.\n",
            "./wavs2/156.wav\n",
            "Campania pare menită să reflecte importanța securității naționale.\n",
            "./wavs2/157.wav\n",
            "Agenții securității de stat s-au grăbit să ajungă la centrul de reciclare.\n",
            "./wavs2/158.wav\n",
            "Agenții au confiscat cărțile și armata a luat măsurile necesare.\n",
            "./wavs2/159.wav\n",
            "În ultimii ani, mai multe firme de consultanță chinezești și străine, care operează în țară, au fost puse sub investigație.\n",
            "./wavs2/160.wav\n",
            "V-am spus de mai multe ori că nu ştiu.\n",
            "./wavs2/161.wav\n",
            "În acest caz, nu există nicio recompensă.\n",
            "./wavs2/162.wav\n",
            "Mi se pare foarte utilă ideea cu energie solară.\n",
            "./wavs2/163.wav\n",
            " ne va aştepta un joc foarte greu.\n",
            "./wavs2/164.wav\n",
            "Aici se pot depune CV-urile.\n",
            "./wavs2/165.wav\n",
            "Nu a fost uşor, dar a meritat.\n",
            "./wavs2/166.wav\n",
            "Banii se întorc la oamenii bogați din păcă.\n",
            "./wavs2/167.wav\n",
            "Te iubesc, dane.\n",
            "./wavs2/168.wav\n",
            "Te iubesc, Ana.\n",
            "./wavs2/169.wav\n",
            "Te iubesc, Andreea.\n",
            "./wavs2/170.wav\n",
            "Cu ce echipă ţii?\n",
            "./wavs2/171.wav\n",
            " ne-am oprit la un mic picnic pe lacul bega.\n",
            "./wavs2/172.wav\n",
            "Universitatea politehnică Timișoara organizează un concurs de diploma.\n",
            "./wavs2/173.wav\n",
            "Din data de doisprezece august, vă puteți înscrie la Facultatea Politehnica Timișoara.\n",
            "./wavs2/174.wav\n",
            "Am urmat şi alte cursuri.\n",
            "./wavs2/175.wav\n",
            "Universitatea politehnică Timișoara, se află lângă centrul Timișoarăi.\n",
            "./wavs2/176.wav\n",
            "Denisa este pasionată de jurnalism.\n",
            "./wavs2/177.wav\n",
            "Dan este doctor.\n",
            "./wavs2/178.wav\n",
            "După pauză, vom reveni la acest subiect.\n",
            "./wavs2/179.wav\n",
            "Fac şi eu ce pot.\n",
            "./wavs2/180.wav\n",
            " Din păcate, de data asta am jucat foarte prost.\n",
            "./wavs2/181.wav\n",
            "Să ne facem oare griji pentru Alexandru?\n",
            "./wavs2/182.wav\n",
            "Pentru țara noastră, este alocat un buget de aproximativ trei milioane de euro.\n",
            "./wavs2/183.wav\n",
            " mama lui nu îl lasă să iasă cu noi afară.\n",
            "./wavs2/184.wav\n",
            " cu siguranţă, eu aş alege o maşină austriacă.\n",
            "./wavs2/185.wav\n",
            "Drumul este blocat pe ambele sensuri, nu avem pe unde trece.\n",
            "./wavs2/186.wav\n",
            "Vreți să vă căsătoriți?\n",
            "./wavs2/187.wav\n",
            "A crescut sub semnul artei.\n",
            "./wavs2/188.wav\n",
            "Universitatea politehnică Timișoara, este o universitate foarte bună.\n",
            "./wavs2/189.wav\n",
            "Dacă învingem joi, vom merge la naţionale.\n",
            "./wavs2/190.wav\n",
            "De atunci, am rămas prieteni foarte buni.\n",
            "./wavs2/191.wav\n",
            " din păcate, jocul a fost foarte slab.\n",
            "./wavs2/192.wav\n",
            "Stratul de ozon se subțiează.\n",
            "./wavs2/193.wav\n",
            "A fost prima oară când i-am auzit vocea.\n",
            "./wavs2/194.wav\n",
            "Ai mașină înseamnă că eşti foarte bogat.\n",
            "./wavs2/195.wav\n",
            "Trebuie să luăm măsuri.\n",
            "./wavs2/196.wav\n",
            "Despre asta este vorba când vorbim de drepturile studentului.\n",
            "./wavs2/197.wav\n",
            " în ce secol trăim?\n",
            "./wavs2/198.wav\n",
            " bărbatul urmează să fie predat poliției.\n",
            "./wavs2/199.wav\n",
            "Nu-l cunosc bine, dar îmi este drag.\n",
            "./wavs2/200.wav\n",
            "Uneori, trebuie să-ţi pui pofta în cui.\n",
            "./wavs2/201.wav\n",
            "Nu este timp de gândit, trebuie să acţionăm.\n",
            "./wavs2/202.wav\n",
            " Deocamdată suntem doar studenți, dar o să terminăm la anul.\n",
            "./wavs2/203.wav\n",
            "Îmi doresc să treacă examenul de licență.\n",
            "./wavs2/204.wav\n",
            "Vreau să devin inginer.\n",
            "./wavs2/205.wav\n",
            "Prețul unui bilet de avion este foarte scump.\n",
            "./wavs2/206.wav\n",
            " doar ce mam întors din vacanță.\n",
            "./wavs2/207.wav\n",
            "Mi-a fost foarte dor de tine.\n",
            "./wavs2/208.wav\n",
            "Îmi este foarte dor de tine.\n",
            "./wavs2/209.wav\n",
            "Viaţa personală şi cea profesională trebuie bine separate.\n",
            "./wavs2/210.wav\n",
            " sunt foarte flămând şi vreau să mănânc.\n",
            "./wavs2/211.wav\n",
            " Zis și făcut, acesta a terminat masa.\n",
            "./wavs2/212.wav\n",
            "Sper să ies curând la pensie.\n",
            "./wavs2/213.wav\n",
            " Mâine, trebuie să mă duc la lucru.\n",
            "./wavs2/214.wav\n",
            " După ce ies de la lucru, o să mă duc la facultate.\n",
            "./wavs2/215.wav\n",
            "Toţi sperăm să treacă iarna repede.\n",
            "./wavs2/216.wav\n",
            "Cinci e un număr ideal.\n",
            "./wavs2/217.wav\n",
            " La fața locului s-au deplasat mai multe echipaje pentru ajutor.\n",
            "./wavs2/218.wav\n",
            "Ai avut o idee foarte bună.\n",
            "./wavs2/219.wav\n",
            "Această chestie ar putea afecta circuitele.\n",
            "./wavs2/220.wav\n",
            "Ultima medie cu care s-a intrat la automatică și calculatoare a fost șapte.\n",
            "./wavs2/221.wav\n",
            "Știu să număr până la zece.\n",
            "./wavs2/222.wav\n",
            " Uită de cum știu să număr. unu, doi, trei, patru, cinci, șase, șapte, opt, nouă, zece.\n",
            "./wavs2/223.wav\n",
            "Iti place cum recit poezie?\n",
            "./wavs2/224.wav\n",
            "Ce mă bucur că a ieșit soarele din nori.\n",
            "./wavs2/225.wav\n",
            " Mia fost chiar dor să stăm împreună.\n",
            "./wavs2/226.wav\n",
            "Nu era obligatoriu să facă asta.\n",
            "./wavs2/227.wav\n",
            "Temele de casă nu sunt obligatorii.\n",
            "./wavs2/228.wav\n",
            "Am mers pe jos până la facultate.\n",
            "./wavs2/229.wav\n",
            "Procurorii îl bănuiesc.\n",
            "./wavs2/230.wav\n",
            "Echipa de elevi a participat la naționale.\n",
            "./wavs2/231.wav\n",
            " îmi place foarte mult să desenez.\n",
            "./wavs2/232.wav\n",
            "Viitorul arată promițător, însă trebuie să muncim pentru el.\n",
            "./wavs2/233.wav\n",
            "Nu pot concepe o viață trăită cu indiferență.\n",
            "./wavs2/234.wav\n",
            "În plus, dacă nu mănânci foarte mult, nu te îngrași.\n",
            "./wavs2/235.wav\n",
            "Toate farfuriile au fost curățate și dezinfectate.\n",
            "./wavs2/236.wav\n",
            "Acum, raportul este în balanță.\n",
            "./wavs2/237.wav\n",
            " Știu că nu suntem perfecți, dar suntem oameni.\n",
            "./wavs2/238.wav\n",
            "Studenții se declară mulțumiți de condițiile din cămine.\n",
            "./wavs2/239.wav\n",
            " ultima medie pentru cămin este opt.\n",
            "./wavs2/240.wav\n",
            "Diseară, eu și prietenii mei mergem la petrecere.\n",
            "./wavs2/241.wav\n",
            "Abia aştept.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Transcriptions saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE5SEOVTPBaU",
        "outputId": "bd061aeb-b066-46ca-8eb9-890df8735ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcriptions saved to ./transcriptions.txt\n"
          ]
        }
      ]
    }
  ]
}